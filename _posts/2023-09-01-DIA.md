---
title: Drone Image Analysis from field data using a Micasense Multispectral sensor
tags:
  - Drone
  - Multispectral
  - En
images01:
  - /fhc-www/_posts/figures/20230901/M1.png
  - /fhc-www/_posts/figures/20230901/M2.png
  - /fhc-www/_posts/figures/20230901/M3.png
  - /fhc-www/_posts/figures/20230901/M4.png
  - /fhc-www/_posts/figures/20230901/M5.png
---


This tutorial contains instructions of how to perform Drone Image analysis for a multispectral sensor. It includes our notes and tips of how to make it simple for a new user. Here we cover the concepts related to mission planning, stitching and plot extraction.

<!--more-->

# Mission

## Before flying: Planning!

You can agree that capturing images with a drone is a fun activity! When we want to capture images from multiple flights and use it for research, is important that we follow some good standards. Here, we want to share how we performed our research in the summer of 2023. We used a DJI Matrice 200 V2 equipped with a Micasense Altum! 

We performed our flights over a winter wheat trial. As any of our drones was equipped with RTK, we first put ground control points (GCPs) in the field and surveyed them using a Multi-band RTK GNSS receiver. MS [Frank Dougher](https://landresources.montana.edu/directory/faculty/2324972/frank-dougher) helped us to survey the points at the field. We used at least five GCPs, four located at the corners of the field and a central GCP.  According to [Pugh *et al* (2021)](https://acsess.onlinelibrary.wiley.com/doi/full/10.1002/ppj2.20026), four GCPs located at the corners of the field should be enough.


## Understanding your sensor and flying

Micasense multispectral sensors are commercialized by [AgEagle](https://ageagle.com/solutions/micasense-series-multispectral-cameras/) and have been used for agricultural applications. We have experience using three sensors in our lab - RedEdge-3, Altum and RedEdge-P. They differ in the resolution of their cameras, but the three of them have five bands in common: Blue, Red, Green, Near Infrared and RedEdge. Altum has an extra thermal sensor, while RedEdge-P has a panchromatic camera.

The settings of a mission should be adjusted according to the sensor. We want a good frontal and side overlap for stitching images later, so we need to fly the drone in a way that we will guarantee these overlaps. We will basically control the number of paths on the flying app according to information like the size of the sensor, resolution, focal length, the triggering interval and the desired overlap. To start, let's take a look in the information of [Micasense Altum](https://support.micasense.com/hc/en-us/articles/360010025413-Altum-Integration-Guide) (serial number AL05) from the official website:

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-0pky"></th>
    <th class="tg-0pky">Multispectral</th>
    <th class="tg-0pky">Thermal</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0pky">Pixel size</td>
    <td class="tg-0pky">3.45 μm</td>
    <td class="tg-0pky">12 μm</td>
  </tr>
  <tr>
    <td class="tg-0pky">Resolution</td>
    <td class="tg-0pky">2064 x 1544 px  (3.2 MP x 5 imagers)</td>
    <td class="tg-0pky">160 x 120 px (0.01 K)</td>
  </tr>
  <tr>
    <td class="tg-0pky">Aspect ratio</td>
    <td class="tg-0pky">4 : 3</td>
    <td class="tg-0pky">4 : 3</td>
  </tr>
  <tr>
    <td class="tg-0pky">Sensor size</td>
    <td class="tg-0pky">7.12 x 5.33 mm  (8.9 mm diagonal)</td>
    <td class="tg-0pky">1.92 x 1.44 mm</td>
  </tr>
  <tr>
    <td class="tg-0pky">Focal length</td>
    <td class="tg-0pky">8 mm</td>
    <td class="tg-0pky">1.77 mm</td>
  </tr>
  <tr>
    <td class="tg-0pky">Field of view (h x v)</td>
    <td class="tg-0pky">48º x 36.8º</td>
    <td class="tg-0pky">57º x 44.3º</td>
  </tr>
  <tr>
    <td class="tg-0pky">Thermal sensitivity</td>
    <td class="tg-0pky">n/a</td>
    <td class="tg-0pky">&lt; 50 mK</td>
  </tr>
  <tr>
    <td class="tg-0pky">Thermal accuracy</td>
    <td class="tg-0pky">n/a</td>
    <td class="tg-0pky">+/- 5 K</td>
  </tr>
  <tr>
    <td class="tg-0pky">Output bit depth</td>
    <td class="tg-0pky">12-bit</td>
    <td class="tg-0pky">14-bit</td>
  </tr>
  <tr>
    <td class="tg-0pky">GSD @ 120 m (~400 ft)</td>
    <td class="tg-0pky">5.2 cm</td>
    <td class="tg-0pky">81 cm</td>
  </tr>
  <tr>
    <td class="tg-0pky">GSD @ 60 m (~200 ft)</td>
    <td class="tg-0pky">2.6 cm</td>
    <td class="tg-0pky">41 cm</td>
  </tr>
</tbody>
</table>


For example, we used the DJI GS Pro to perform our missions. In this app, we can enter a custom camera and the information we needed was the resolution, the sensor size (it's the size of each one of the five little cameras, not the structural size of the sensor) and focal length. See that we have two kinds of sensors, where thermal has less resolution than the multispectral ones. You need to choose which one of them helps you to achieve your research goals. For us, the objective was to use the data from the five multispectral band, so all our mission planning was focused on them.

 We configured the Altum to capture images in the overlap mode, asking for at least 85% overlap (do not forget to set up the target height). In the GS Pro app we set settings to 80% frontal and side overlap, keeping the speed of the drone around 3 to 4 mph. A very important point here is that you need to define the height of your missions! We had good experiences flying 90 and 50 ft, but there is no rule of thumb as it depends on the crop and objectives of the research. Choosing the height, increasing the overlap and controlling the speed might affect a lot the time of the flight, so you need to study how to optimize it for your conditions! A good advice is to play with your settings in test flights before you really start collecting the data. The good part is that after your mission is defined, you can use the same settings through the season!


## Check your images - FlightCheck

A good practice is to check your SD card after performing a mission, to be sure the images were saved. Unfortunately, our RedEdge-3 failed in some flights and, by checking our data, we could fly again the same field when we found problems. Well, for long missions, we know that it is a little boring to scan through all folders, especially because we have the same picture in multiple spectra. Also, sometimes there is no time to stitch the images and assess if the orthomosaic is complete. Imagine spending a good amount of time flying, stitching and getting a result like this in the end:

![]({{ site.baseurl}}{% link _posts/figures/20230901/ww_20230622_failed.png %}){:width="80%"}

Not ideal, right? It looks like a green Pac-Man or a [Rex](https://disney.fandom.com/wiki/Rex)! What happened in this flight is a very good example of a problem with the sensor. This was a long mission where we had to stop twice to change the battery, requiring us to turn off and on the drone. For some reason, when we took off the second time, RedEdge-3 did not save pictures in the SD card. To help with cases like these we created [FlightCheck](https://github.com/Lachowiec-Lab/FlightCheck), a very simple app where you can upload images and where pictures were taken in the field. It's possible to evaluate if you have all the paths as expected in the mission. There are two simple ways to use it: as a Shiny app on RStudio, or directly on the [website](https://correrfh.shinyapps.io/flightcheck/). The main difference is that in the first you can give the path of a folder with subfolders containing images; while in the latter you need to upload images to the website. For instructions please check the [FlightCheck](https://github.com/Lachowiec-Lab/FlightCheck) GitHub page.


# Stitching using Open Drone Map

We have been using open source tools in our lab for all the data processing. It would not be different for stitching! This task can be accomplished by [Open Drone Map](https://www.opendronemap.org), a very elegant effort to create an open ecosystem for drone image analysis! We have been using mostly the [command line toolkit](https://www.opendronemap.org/odm/) via [Docker](https://www.docker.com/) for stitching in the high performance computer. We also recommend installing [WebODM](https://www.opendronemap.org/webodm/) locally if you surveyed ground control points! The tutorials for installation are excellent, but feel free to contact us if you need some extra help!

**Let's get started!**

Here are tips from our experience stitching multispectral images. There are probably other ways to do some of the following steps!

## Multispectral images

Micasense sensors capture the bands in separate TIF files. Here are images for five bands (we did not include the thermal band from Altum):

<div class="card-columns">
    {% for img in page.images01 %}
    <div class="card">
        <img class="card-img-top" src="{{ img }}" />
    </div>
    {% endfor %}
</div>

To identify the pixels associated to the GCPs' coordinates, we will use WebODM. However, it only accepts PNG or JPG images. For that reason, we will choose one of the bands and convert it to PNG. On MacOS we can easily select images with a certain extension and convert them to the desired format. But we can make it simpler! We can install [ImageMagick](https://imagemagick.org/index.php) (search on Internet the easiest way to install it in your sytem) to use the function `mogrify` to convert TIF into JPG:

`mogrify -format jpg *_3.tif`

If you are in a folder with Micasense TIF images, this command will create JPG files from them. We used `*_3.tif` to select only the files finishing in `_3.tif`, as we only want images from the red band (in our experience, it was easier to find the central point of the GCP using red or NIR). 

### Note about folders

In a normal flight, Micasense saves a folder with multiple subfolders inside. If the SD card is empty, the first folder will be `0000SET`. If you turn the drone off and on again, it will create `0001SET`! Let's suppose that you turned on the drone, took pictures of the reflectance panel, turned it off, positioned it and turned it on for the mission. This will make you have `0000SET` containing a `000` subfolder with images of the panel, and `0001SET` with multiple subfolders (`000`,`001`,`0002`,...) with the images of the flight. You would use the images inside the `0001SET` for stitching. It will be easy because their identifiers **will not be repeated** and it will be essential for ODM later. Please take a look to be sure the identifiers in the subfolders are not the same!!!

For flights where you need to change your battery, multiple SET folders will be used - `0000SET`, `0001SET` and so on. The problem here is that now the images in the subfolders have the same identifiers. Suppose that we started the mission and images were saved to `0000SET`, we stopped the drone to change its battery and continued from the point where we started so that a new folder `0001SET` will be created. The first image on `0000SET/000/` is `IMG_0000_1.tif` (`_1.tif` indicates it is the first band) and the first image on `0001SET/000/` is also `IMG_0000_1.tif`! If we do not rename the identifiers, it can cause a big problem during stitching when you put all the images in the same folder (one set will be overwritten by the other). Avoid it by renaming properly!

## Identifying the GCPs

After the surveying the GCP, the data needs to be processed, and you need to identify some important information:

- The coordinate system and map projection (usually a `.prj`) file. It needs to be formatted and included as the first line of the GCP file that will be used for stitching. For more information please take a look at the [guideline](https://docs.opendronemap.org/gcp/).
- A spatial index file (`.sbn`) containing the GCP name and information about Northing, Easting and elevation.


